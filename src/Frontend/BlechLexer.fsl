{
// Copyright (c) 2019 - for information on the respective copyright owner
// see the NOTICE file and/or the repository 
// https://github.com/boschresearch/blech.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

module Blech.Frontend.BlechLexer

open SyntaxUtils
open LexerUtils
open ParserUtils
open BlechParser

open Blech.Common

// end of F# helping functions

}

(* Lexer regex rules *)

(* all combinations of ascii end of line sequences *)
let endofline = ( '\r' '\n' | '\n' '\r' | '\n' | '\r' )

(* numbers and bitvecs follow https://www.python.org/dev/peps/pep-0515/ *)
let hexdigit = ['0'-'9' 'a'-'f' 'A'-'F']

let binliteral = "0b"('_'? ['0'-'1'])+
let octliteral = "0o"('_'? ['0'-'7'])+
let hexliteral = "0x"('_'? hexdigit)+  

let digit = ['0' - '9']
let nonzerodigit = ['1' - '9']
let nonzero = nonzerodigit ('_'? digit)*
let zero = '0' ('_'? '0')*
let natliteral = (nonzero | zero)

(* float literals *)
let digitpart = digit ('_'? digit)*
let fraction = '.' digitpart
let exponent = ('e' | 'E') ('+' | '-')? digitpart
let pointfloat = digitpart? fraction | digitpart '.'
let exponentfloat = (digitpart | pointfloat) exponent
let floatliteral = (pointfloat | exponentfloat)

(* hexadecimal floating point literals with "_" instead of "'" follow
   C++17 http://en.cppreference.com/w/cpp/language/floating_literal and 
   C99 http://en.cppreference.com/w/c/language/floating_constant  *)
let hexdigitpart = hexdigit ('_'? hexdigit)* 
let hexfraction = '.' hexdigitpart
let hexexponent = ('p' | 'P') ('+' | '-')? digitpart
let hexpointfloat = hexdigitpart? hexfraction | hexdigitpart '.'
let hexexponentfloat = (hexdigitpart | hexpointfloat) hexexponent
let hexfloatliteral = "0x"'_'? hexexponentfloat

(* strings and multi-line strings follow Julia https://docs.julialang.org/en/v1/manual/strings/
   line continuations are allowed for both
   escape sequence checking follows Lua https://www.lua.org/manual/5.4/manual.html#3.1 *)

let linecontinuation = '\\' endofline

let unicodelineending = ['\u0085' '\u2028' '\u2029'] // generally invalid

let stringchar = [^ '\\' '"' '\x00'-'\x1f' '\x7f'-'\xff']  // printable unicode only  

let escape = '\\' ['a' 'b' 'f' 'n' 'r' 't' 'v' '\\' '\'' '\"']
let hexescape = '\\' 'x' hexdigit hexdigit
let decimalescape = '\\' digit digit? digit?
let unicodeescape = '\\' 'u' '{' hexdigit+ '}'

let stringitem = stringchar | escape | hexescape

let triplequotes = "\"\"\""
let quotes = '"' '"'?

let characterchar = [^ '\\' '\'' '\x00'-'\x1f' '\x7f'-'\xff']  // printable unicode only  
let charitem = characterchar | escape | hexescape
let characterliteral = '\'' charitem '\''

let identifier = '_'*['a'-'z' 'A'-'Z']+['_' 'a'-'z' 'A'-'Z' '0'-'9']* 

let path = '<' [^ '>''.''/''\\'] [^'>''\\']* '>' 

let chunkwithoutnewline = [^'\n' '\r']*
let chunkwithoutstar = [^'*' '\n' '\r']*

let chunkwithoutstarandslash = [^'*' '/' '\n' '\r']*

rule Token = parse

    (* ---- doc comments, comments and whitespaces ---- *)

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              Token lexbuf }

    | ' '                   { Token lexbuf }

    | '\t'+                 { // tabs for identation at the start of a line are allowed
                              if lexbuf.StartPos.Column > 0 then tabularUsed lexbuf else ()
                              Token lexbuf }
    
    | "/*"                  { commentDepth <- 1; 
                              commentStart <- Some (getRange lexbuf);
                              SkipBlockComment lexbuf }
    
    | "//"                  { SkipLineComment lexbuf } 

    (* --- strings --- *)

    | '"'                   { tokenBuilder <- tokenBuilder.Init (getRange lexbuf)
                              CollectSingleLineString lexbuf }

    | triplequotes          { tokenBuilder <- tokenBuilder.Init (getRange lexbuf)
                              CollectMultiLineString lexbuf }

    (* ---- doc comments ---- *)

    | "///"                 { tokenBuilder <- tokenBuilder.Init (getRange lexbuf) 
                              CollectLineDoc lexbuf } 
    
    | "/**"                 { tokenBuilder <- tokenBuilder.Init (getRange lexbuf) 
                              CollectBlockDoc lexbuf } 

    (* ---- file system: reserved directory name for blech transpilations ---- *)
    | "blech"               { BLECH (getRange lexbuf) }
    
    (* ---- module system ---- *)
    | "module"              { MODULE (getRange lexbuf) }
    | "import"              { IMPORT (getRange lexbuf) }
    | "from"                { fromStart <- getRange lexbuf
                              FromPath lexbuf } 
    | "exposes"             { EXPOSES (getRange lexbuf) }
    | "signature"           { SIGNATURE (getRange lexbuf) }

    (* --- extensions --- *)
    
    | "extension"           { EXTENSION (getRange lexbuf) }

    (* ---- predefined types ---- *)

    | "bool"                { BOOL (getRange lexbuf) }

    | "bits8"               { BITS8 (getRange lexbuf) }
    | "bits16"              { BITS16 (getRange lexbuf) }
    | "bits32"              { BITS32 (getRange lexbuf) }
    | "bits64"              { BITS64 (getRange lexbuf) }

    | "nat8"               { NAT8 (getRange lexbuf) }
    | "nat16"              { NAT16 (getRange lexbuf) }
    | "nat32"              { NAT32 (getRange lexbuf) }
    | "nat64"              { NAT64 (getRange lexbuf) }

    | "int8"                { INT8 (getRange lexbuf) }
    | "int16"               { INT16 (getRange lexbuf) }
    | "int32"               { INT32 (getRange lexbuf) }
    | "int64"               { INT64 (getRange lexbuf) }

    | "float32"             { FLOAT32 (getRange lexbuf) }
    | "float64"             { FLOAT64 (getRange lexbuf) }

    (* --- user-defined types --- *)

    | "type"                { TYPE (getRange lexbuf) }
    | "newtype"             { NEWTYPE (getRange lexbuf) }
    | "enum"                { ENUM (getRange lexbuf) }
    | "struct"              { STRUCT (getRange lexbuf) }

    (* --- signals --- *)
    | "signal"              { SIGNAL (getRange lexbuf) }
    
    (* --------- units of measure --------- *)
    | "unit"                { UNIT (getRange lexbuf) }

    (* --- clocks --- *)
    | "clock"               { CLOCK (getRange lexbuf) }
    | "count"               { COUNT (getRange lexbuf) }
    | "up"                  { UP (getRange lexbuf) }
    | "down"                { DOWN (getRange lexbuf) }
    | "off"                 { OFF (getRange lexbuf) }
    | "join"                { JOIN (getRange lexbuf) }
    | "meet"                { MEET (getRange lexbuf) }
    | "tick"                { TICK (getRange lexbuf) }
    | "on"                  { ON (getRange lexbuf) }

    (* --------- actions --------- *)

    | "emit"                { EMIT (getRange lexbuf) }
    | "past"                { PAST (getRange lexbuf) }
    | "="                   { ASSIGN (getRange lexbuf) }
    | "assume"              { ASSUME (getRange lexbuf) }
    | "assert"              { ASSERT (getRange lexbuf) }
    
    (* --------- types, activties, functions --------- *)

    | "activity"            { ACTIVITY (getRange lexbuf) }
    | "function"            { FUNCTION (getRange lexbuf) }
    | "var"                 { VAR (getRange lexbuf) }
    | "let"                 { LET (getRange lexbuf) }
    | "ref"                 { REF (getRange lexbuf) }

    | "singleton"           { SINGLETON (getRange lexbuf) }
    | "param"               { PARAM (getRange lexbuf) }
    | "const"               { CONST (getRange lexbuf) }
    
    | "shares"              { SHARES (getRange lexbuf) }

    (* ----- FFI ------ *)
    | "extern"              { EXTERN (getRange lexbuf) }

    (* --------- Blech statements --------- *)

    | "abort"               { ABORT (getRange lexbuf) }
    | "await"               { AWAIT (getRange lexbuf) }
    | "cobegin"             { COBEGIN (getRange lexbuf) }
    | "default"             { DEFAULT (getRange lexbuf) }
    | "do"                  { DO (getRange lexbuf) }
    | "else"                { ELSE (getRange lexbuf) }
    | "elseif"              { ELSEIF (getRange lexbuf) }
    | "end"                 { END (getRange lexbuf) }
    | "for"                 { FOR (getRange lexbuf) }
    | "if"                  { IF (getRange lexbuf) }
    | "in"                  { IN (getRange lexbuf) }
    | "of"                  { OF (getRange lexbuf) }
    | "print"               { PRINT (getRange lexbuf) }
    | "repeat"              { REPEAT (getRange lexbuf) }
    | "run"                 { RUN (getRange lexbuf) }
    | "reset"               { RESET (getRange lexbuf) }
    | "return"              { RETURN (getRange lexbuf) }
    | "returns"             { RETURNS (getRange lexbuf) }
    | "suspend"             { SUSPEND (getRange lexbuf) }
    | "then"                { THEN (getRange lexbuf) }
    | "until"               { UNTIL (getRange lexbuf) }
    | "weak"                { WEAK (getRange lexbuf) }
    | "when"                { WHEN (getRange lexbuf) }
    | "while"               { WHILE (getRange lexbuf) }
    | "with"                { WITH (getRange lexbuf) }
    | "try"                 { TRY (getRange lexbuf) }
    | "throw"               { THROW (getRange lexbuf) }
    | "throws"              { THROWS (getRange lexbuf) }

    (* ----- error handling -----*)
    | "error"               { ERROR (getRange lexbuf) }

    (* --------- expressions and operators --------- *)

    | "true"                { TRUE (getRange lexbuf) }
    | "false"               { FALSE (getRange lexbuf) }
  
    (* logical operators *)
    | "not"                 { NOT (getRange lexbuf) }
    | "and"                 { AND (getRange lexbuf) }
    | "or"                  { OR (getRange lexbuf) }
        
    (* arithmetic operators *)
    | "+"                   { ADD (getRange lexbuf) }
    | "-"                   { SUB (getRange lexbuf) } // also unary minus
    | "*"                   { MUL (getRange lexbuf) }
    | "/"                   { DIV (getRange lexbuf) }
    | "%"                   { MOD (getRange lexbuf) }
    | "**"                  { EXP (getRange lexbuf) }
    
    (* bitwise operators *)
    | "&"                   { BAND (getRange lexbuf) }
    | "|"                   { BOR (getRange lexbuf) }
    | "^"                   { BXOR (getRange lexbuf) }
    | "~"                   { BNOT (getRange lexbuf) }
    | "<<"                  { SHL (getRange lexbuf) }
    | ">>"                  { SHR (getRange lexbuf) }

    (* advanced bitwise operators *)
    | "+>>"                  { SSHR (getRange lexbuf) } // signed shift right  
    | "<<>"                  { ROTL (getRange lexbuf) } // rotate left
    | "<>>"                  { ROTR (getRange lexbuf) } // rotate right   
    
    (* relational operators *)
    | "=="                  { EQU (getRange lexbuf) }
    | "!="                  { IEQ (getRange lexbuf) }
    | "<"                   { LES (getRange lexbuf) }
    | "<="                  { LEQ (getRange lexbuf) }
    | ">"                   { GRT (getRange lexbuf) }
    | ">="                  { GEQ (getRange lexbuf) }

    (* identity operators *)
    | "==="                 { IDEQU (getRange lexbuf) }
    | "!=="                 { IDIEQ (getRange lexbuf) }

    (* static cast *)
    | "as"                  { AS (getRange lexbuf) }

    (* forced cast *)
    | "as!"                 { ASBANG (getRange lexbuf) } 

    (* annotations *)
    | "@"                   { AT (getRange lexbuf) }
    | "@@"                  { ATAT (getRange lexbuf) }

    (* length operators on arrays and slices *)
    | "#"                   { LEN (getRange lexbuf) }    
    | "##"                  { CAP (getRange lexbuf) }

    (* -------------- Access operators ------------*)
    | "prev"                { PREV (getRange lexbuf) }
    | "next"                { NEXT (getRange lexbuf) }

    

    (* --------- delimiters and punctuations --------- *)

    | "{"                   { LBRACE (getRange lexbuf) }
    | "}"                   { RBRACE (getRange lexbuf) }
    | "["                   { LBRACKET (getRange lexbuf) }
    | "]"                   { RBRACKET (getRange lexbuf) }
    | "("                   { LPAREN (getRange lexbuf) }
    | ")"                   { RPAREN (getRange lexbuf) }
    | "..."                 { ELLIPSIS (getRange lexbuf) }
    | "."                   { POINT (getRange lexbuf) }
    | ":"                   { COLON (getRange lexbuf) }
    | ","                   { COMMA (getRange lexbuf) }
    | ";"                   { SEMICOLON (getRange lexbuf) }
    | "?"                   { QUEST (getRange lexbuf) }

    (* --------- literals --------- *)

    | binliteral            { BINCONST  (getLexemeAndRange lexbuf) }
    
    | octliteral            { OCTCONST (getLexemeAndRange lexbuf) }
    
    | hexliteral            { HEXCONST (getLexemeAndRange lexbuf) }

    | natliteral            { NATCONST (getLexemeAndRange lexbuf) }

    | floatliteral          { FLOATCONST (getLexemeAndRange lexbuf) }

    | hexfloatliteral       { HEXFLOATCONST (getLexemeAndRange lexbuf) }

    | identifier            { ID (getLexemeAndRange lexbuf) }

    | '_'+                  { WILDCARD (getLexemeAndRange lexbuf) }

    (* --------- end of file and invalid source code characters  --------- *)

    | eof                   { EOF (getRange lexbuf) }

    | _                     { unknownToken lexbuf;  // any other unicode character
                              Token lexbuf }


(* fjg: returns the next token after the comment, in order to make EOF available in case of unterminated comment *)
and SkipBlockComment = parse     

    | "*/"                  { commentDepth <- commentDepth - 1;
                              if commentDepth = 0 then
                                  commentStart <- None;
                                  Token lexbuf
                              else 
                                  SkipBlockComment lexbuf }
       
    | "/*"                  { commentDepth <- commentDepth + 1;
                              SkipBlockComment lexbuf }

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              SkipBlockComment lexbuf }

    | eof                   { commentNotClosed lexbuf; 
                              EOF (getRange lexbuf) }


    | chunkwithoutstarandslash
                            { SkipBlockComment lexbuf }

    | '/'                   { SkipBlockComment lexbuf }

    | "*"                   { SkipBlockComment lexbuf }



and SkipLineComment = parse
    | chunkwithoutnewline   { Token lexbuf }

and SkipLineOnError = parse
    | endofline             { let eol = EOL (getRange lexbuf) in
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine;
                              ParserContext.setErrorTokenAccepted false; 
                              eol}

    | eof                   { ParserContext.setErrorTokenAccepted false; 
                              EOF (getRange lexbuf)}

    | chunkwithoutnewline   { SkipLineOnError lexbuf }


and CollectLineDoc = parse    
    | chunkwithoutnewline   { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectLineDoc lexbuf }

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine 
                              LINEDOC (tokenBuilder.Token) }
                              
    | eof                   { eofInDocComment (tokenBuilder.Range) 
                              EOF (getRange lexbuf) }

    
and CollectBlockDoc = parse
    | chunkwithoutstar      { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectBlockDoc lexbuf }

    | "*"                   { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectBlockDoc lexbuf }
    
    | endofline             { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectBlockDoc lexbuf }
    

    | "*/"                  { BLOCKDOC (tokenBuilder.Token) }

    | eof                   { eofInDocComment (tokenBuilder.Range)
                              EOF (getRange lexbuf) }

and CollectSingleLineString = parse   // TODO: Move token checking - e.g. decimal and unicode escapes, utf8endofline, ascii control chars to lexer, fjg. 18.08.20

    | linecontinuation      { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf) // '\'<endofline> removed after indentation handling
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine
                              CollectSingleLineString lexbuf }

    | endofline             { let lxm, rng = getLexemeAndRange lexbuf
                              eolInSingleLineString rng
                              tokenBuilder <- tokenBuilder.Append (lxm, rng)
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectSingleLineString lexbuf }

    | '\t'                  { // tabs are not allowed strings
                              tabularUsed lexbuf
                              CollectSingleLineString lexbuf }

    | unicodelineending     { unknownToken lexbuf;
                              CollectSingleLineString lexbuf }

    | '"'                   { STRING (tokenBuilder.Token) }

    | decimalescape         { let decEsc = getLexemeAndRange lexbuf
                              checkDecimalEscape decEsc
                              tokenBuilder <- tokenBuilder.Append decEsc
                              CollectSingleLineString lexbuf }

    | unicodeescape         { let uniEsc = getLexemeAndRange lexbuf
                              checkUnicodeEscape uniEsc
                              tokenBuilder <- tokenBuilder.Append uniEsc
                              CollectSingleLineString lexbuf }
        
    | stringitem
                            { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectSingleLineString lexbuf }
        

    | eof                   { eofInDocComment (tokenBuilder.Range)  // Todo: Create separate error message, fjg. 5.8.20
                              EOF (getRange lexbuf) }

    | _                     { unknownToken lexbuf; 
                              CollectSingleLineString lexbuf }

and CollectMultiLineString = parse

    | linecontinuation      { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf) // '\'<endofline> removed after indentation handling
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine
                              CollectMultiLineString lexbuf }

    | endofline             { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectMultiLineString lexbuf }

    | '\t'+                 { // tabs for identation at the start of a line are allowed in multi-line strings
                              if lexbuf.StartPos.Column > 0 then tabularUsed lexbuf else ()
                              CollectMultiLineString lexbuf }

    | unicodelineending     { unknownToken lexbuf; 
                              CollectMultiLineString lexbuf }
    
    | triplequotes          { MULTILINESTRING (tokenBuilder.Token) }    

    | decimalescape         { let decEsc = getLexemeAndRange lexbuf
                              checkDecimalEscape decEsc
                              tokenBuilder <- tokenBuilder.Append decEsc
                              CollectMultiLineString lexbuf }

    | unicodeescape         { let uniEsc = getLexemeAndRange lexbuf
                              checkUnicodeEscape uniEsc
                              tokenBuilder <- tokenBuilder.Append uniEsc
                              CollectMultiLineString lexbuf }
        
    | stringitem
                            { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectMultiLineString lexbuf }
    
    | quotes                { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectMultiLineString lexbuf }

    | eof                   { eofInDocComment (tokenBuilder.Range)
                              EOF (getRange lexbuf) }

    | _                     { unknownToken lexbuf
                              CollectMultiLineString lexbuf }


and FromPath = parse
    | path                  { let path, rng = getLexemeAndRange lexbuf in
                              FROMPATH {Blech.Frontend.AST.FromPath.path = path
                                        range = Range.unionRanges fromStart rng } }

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              FromPath lexbuf }
    
    | [' ']                 { FromPath lexbuf }

    | ['\t']                { tabularUsed lexbuf; 
                              FromPath lexbuf }

    | _                     { notAPath lexbuf;
                              Token lexbuf }