{
// Copyright (c) 2019 - for information on the respective copyright owner
// see the NOTICE file and/or the repository 
// https://github.com/boschresearch/blech.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

module Blech.Frontend.BlechLexer

open SyntaxUtils
open LexerUtils
open ParserUtils
open BlechParser

open Blech.Common

// end of F# helping functions

}

(* Lexer regex rules *)

let endofline = ( '\r' '\n' | '\n' '\r' | '\n' | '\r' )


(* numbers and bitvecs follow https://www.python.org/dev/peps/pep-0515/ *)

let binliteral = "0b"('_'?['0'-'1'])+
let octliteral = "0o"('_'?['0'-'7'])+
let hexliteral = "0x"('_'?['0'-'9' 'a'-'f' 'A'-'F'])+  

let digit = ['0' - '9']
let nonzerodigit = ['1' - '9']
let nonzero = nonzerodigit ('_'? digit)*
let zero = '0' ('_'? '0')*
let natliteral = (nonzero | zero)

(* float literals have a specified precision
   this is unlike Swift where literals are assumed to be Double *)

let digitpart = ['0'-'9']('_'?['0'-'9'])*
let fraction = '.' digitpart
let exponent = ('e' | 'E') ('+' | '-')? digitpart
let pointfloat = digitpart? fraction | digitpart '.'
let exponentfloat = (digitpart | pointfloat) exponent
let floatliteral = (pointfloat | exponentfloat)

(* hexadecimal floating point literals with "_" instead of "'" follow
   C++17 http://en.cppreference.com/w/cpp/language/floating_literal and 
   C99 http://en.cppreference.com/w/c/language/floating_constant  *)
let hexdigit = ['0'-'9' 'a'-'f' 'A'-'F']
let hexdigitpart = hexdigit ('_'? hexdigit)* 
let hexfraction = '.' hexdigitpart
let hexexponent = ('p' | 'P') ('+' | '-')? digitpart
let hexpointfloat = hexdigitpart? hexfraction | hexdigitpart '.'
let hexexponentfloat = (hexdigitpart | hexpointfloat) hexexponent
let hexfloatliteral = "0x"'_'? hexexponentfloat

(* strings and triplequotedstrings follow Julia https://docs.julialang.org/en/v1/manual/strings/
   line continuations are allowed for both
   escape sequence checking follows Lua https://www.lua.org/manual/5.4/manual.html#3.1 *)

(* Invalid UTF8 end of line characters *)
let utf8endofline = 
      "\xc2\x85"      // next line: U+0085
    | "\xe2\x80\xa8"  // line separator: U+2028
    | "\xe2\x80\xa8"  // paragraph: U+2029 

let asciiprintable = ['\x20'-'\x7E']
let utf8cont = ['\x80'-'\xbf']
let utf8enc = ['\xc2'-'\xdf'] utf8cont 
    | ['\xe0'] ['\xa0'-'\xbf'] utf8cont 
    | ['\xed'] ['\x80'-'\x9f'] utf8cont
    | ['\xe1'-'\xec''\xee'-'\xef'] utf8cont utf8cont
    | ['\xf0'] ['\x90'-'\xbf'] utf8cont utf8cont
    | ['\xf4'] ['\x80'-'\x8f'] utf8cont utf8cont
    | ['\xf1'-'\xf3'] utf8cont utf8cont utf8cont

// utf8charpattern = '\\' [\0-\x7F\xC2-\xFD][\x80-\xBF]*   // utf8 char pattern, see https://www.lua.org/manual/5.4/manual.html#6.5

// let anychar = [^ '\n' '\r']       // end of line is handled by the token parser

//let stringchar = [^ '\\' '"' '\n' '\r']  

let stringchar = [^ '\\' '"' '\x00'-'\x1f' '\x7f'-'\xff']  

let escapeseq = '\\' asciiprintable? 

let escape = '\\' ['a' 'b' 'f' 'n' 'r' 't' 'v' '\\' '\'' '\"']
let hexescape = '\\' 'x' hexdigit hexdigit
let decimalescape = '\\' digit digit? digit?
let unicodeescape = '\\' 'u' '{' hexdigitpart '}'
let linecontinuation = '\\'    // TODO: make escape checking part of the parser, fjg. 18.08.20

//let stringitem = stringchar | utf8enc | escapeseq

let stringitem = stringchar | utf8enc | escape | hexescape | decimalescape | unicodeescape | linecontinuation

let stringitems = stringitem*


let triplequotes = "\"\"\""
let quotes = '"' '"'?

let path = '<' [^ '>''.''/''\\'] [^'>''\\']* '>' 

let chunkwithoutnewline = [^'\n' '\r']*
let chunkwithoutstar = [^'*' '\n' '\r']*

let chunkwithoutstarandslash = [^'*' '/' '\n' '\r']*

rule Token = parse

    (* ---- doc comments, comments and whitespaces ---- *)
    | ['\t']                { // tabularUsed lexbuf; 
                              Token lexbuf }
    
    | "/*"                  { commentDepth <- 1; 
                              commentStart <- Some (getRange lexbuf);
                              SkipBlockComment lexbuf }
    
    | "//"                  { SkipLineComment lexbuf } 
    
    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              Token lexbuf }
    
    | [' ']                 { Token lexbuf }

    (* --- strings, can span multiple lines --- *)

    | '"'                   { let lxm, rng = getLexemeAndRange lexbuf
                              tokenBuilder <- tokenBuilder.Init rng
                              tokenBuilder <- tokenBuilder.Append (lxm, rng)
                              CollectString lexbuf }

    | triplequotes          { let lxm, rng = getLexemeAndRange lexbuf
                              tokenBuilder <- tokenBuilder.Init rng
                              tokenBuilder <- tokenBuilder.Append (lxm, rng)
                              CollectTripleQuotedString lexbuf }

    (* ---- doc comments ---- *)

    | "///"                 { tokenBuilder <- tokenBuilder.Init (getRange lexbuf) 
                              CollectLineDoc lexbuf } 
    
    | "/**"                 { tokenBuilder <- tokenBuilder.Init (getRange lexbuf) 
                              CollectBlockDoc lexbuf } 

    (* ---- file system: reserved directory name for blech transpilations ---- *)
    | "blech"               { BLECH (getRange lexbuf) }
    
    (* ---- module system ---- *)
    | "module"              { MODULE (getRange lexbuf) }
    | "import"              { IMPORT (getRange lexbuf) }
    | "from"                { fromStart <- getRange lexbuf
                              FromPath lexbuf } 
    | "exposes"             { EXPOSES (getRange lexbuf) }
    | "signature"           { SIGNATURE (getRange lexbuf) }

    (* --- extensions --- *)
    
    | "extension"           { EXTENSION (getRange lexbuf) }

    (* ---- predefined types ---- *)

    | "bool"                { BOOL (getRange lexbuf) }

    | "bits8"               { BITS8 (getRange lexbuf) }
    | "bits16"              { BITS16 (getRange lexbuf) }
    | "bits32"              { BITS32 (getRange lexbuf) }
    | "bits64"              { BITS64 (getRange lexbuf) }

    | "nat8"               { NAT8 (getRange lexbuf) }
    | "nat16"              { NAT16 (getRange lexbuf) }
    | "nat32"              { NAT32 (getRange lexbuf) }
    | "nat64"              { NAT64 (getRange lexbuf) }

    | "int8"                { INT8 (getRange lexbuf) }
    | "int16"               { INT16 (getRange lexbuf) }
    | "int32"               { INT32 (getRange lexbuf) }
    | "int64"               { INT64 (getRange lexbuf) }

    | "float32"             { FLOAT32 (getRange lexbuf) }
    | "float64"             { FLOAT64 (getRange lexbuf) }

    (* --- user-defined types --- *)

    | "type"                { TYPE (getRange lexbuf) }
    | "newtype"             { NEWTYPE (getRange lexbuf) }
    | "enum"                { ENUM (getRange lexbuf) }
    | "struct"              { STRUCT (getRange lexbuf) }

    (* --- signals --- *)
    | "signal"              { SIGNAL (getRange lexbuf) }
    
    (* --------- units of measure --------- *)
    | "unit"                { UNIT (getRange lexbuf) }

    (* --- clocks --- *)
    | "clock"               { CLOCK (getRange lexbuf) }
    | "count"               { COUNT (getRange lexbuf) }
    | "up"                  { UP (getRange lexbuf) }
    | "down"                { DOWN (getRange lexbuf) }
    | "off"                 { OFF (getRange lexbuf) }
    | "join"                { JOIN (getRange lexbuf) }
    | "meet"                { MEET (getRange lexbuf) }
    | "tick"                { TICK (getRange lexbuf) }
    | "on"                  { ON (getRange lexbuf) }

    (* --------- actions --------- *)

    | "emit"                { EMIT (getRange lexbuf) }
    | "past"                { PAST (getRange lexbuf) }
    | "="                   { ASSIGN (getRange lexbuf) }
    | "assume"              { ASSUME (getRange lexbuf) }
    | "assert"              { ASSERT (getRange lexbuf) }
    
    (* --------- types, activties, functions --------- *)

    | "activity"            { ACTIVITY (getRange lexbuf) }
    | "function"            { FUNCTION (getRange lexbuf) }
    | "var"                 { VAR (getRange lexbuf) }
    | "let"                 { LET (getRange lexbuf) }
    | "ref"                 { REF (getRange lexbuf) }

    | "singleton"           { SINGLETON (getRange lexbuf) }
    | "param"               { PARAM (getRange lexbuf) }
    | "const"               { CONST (getRange lexbuf) }
    
    | "shares"              { SHARES (getRange lexbuf) }

    (* ----- FFI ------ *)
    | "extern"              { EXTERN (getRange lexbuf) }

    (* --------- Blech statements --------- *)

    | "abort"               { ABORT (getRange lexbuf) }
    | "await"               { AWAIT (getRange lexbuf) }
    | "cobegin"             { COBEGIN (getRange lexbuf) }
    | "default"             { DEFAULT (getRange lexbuf) }
    | "do"                  { DO (getRange lexbuf) }
    | "else"                { ELSE (getRange lexbuf) }
    | "elseif"              { ELSEIF (getRange lexbuf) }
    | "end"                 { END (getRange lexbuf) }
    | "for"                 { FOR (getRange lexbuf) }
    | "if"                  { IF (getRange lexbuf) }
    | "in"                  { IN (getRange lexbuf) }
    | "of"                  { OF (getRange lexbuf) }
    | "print"               { PRINT (getRange lexbuf) }
    | "repeat"              { REPEAT (getRange lexbuf) }
    | "run"                 { RUN (getRange lexbuf) }
    | "reset"               { RESET (getRange lexbuf) }
    | "return"              { RETURN (getRange lexbuf) }
    | "returns"             { RETURNS (getRange lexbuf) }
    | "suspend"             { SUSPEND (getRange lexbuf) }
    | "then"                { THEN (getRange lexbuf) }
    | "until"               { UNTIL (getRange lexbuf) }
    | "weak"                { WEAK (getRange lexbuf) }
    | "when"                { WHEN (getRange lexbuf) }
    | "while"               { WHILE (getRange lexbuf) }
    | "with"                { WITH (getRange lexbuf) }
    | "try"                 { TRY (getRange lexbuf) }
    | "throw"               { THROW (getRange lexbuf) }
    | "throws"              { THROWS (getRange lexbuf) }

    (* ----- error handling -----*)
    | "error"               { ERROR (getRange lexbuf) }

    (* --------- expressions and operators --------- *)

    | "true"                { TRUE (getRange lexbuf) }
    | "false"               { FALSE (getRange lexbuf) }
  
    (* logical operators *)
    | "not"                 { NOT (getRange lexbuf) }
    | "and"                 { AND (getRange lexbuf) }
    | "or"                  { OR (getRange lexbuf) }
        
    (* arithmetic operators *)
    | "+"                   { ADD (getRange lexbuf) }
    | "-"                   { SUB (getRange lexbuf) } // also unary minus
    | "*"                   { MUL (getRange lexbuf) }
    | "/"                   { DIV (getRange lexbuf) }
    | "%"                   { MOD (getRange lexbuf) }
    | "**"                  { EXP (getRange lexbuf) }
    
    (* bitwise operators *)
    | "&"                   { BAND (getRange lexbuf) }
    | "|"                   { BOR (getRange lexbuf) }
    | "^"                   { BXOR (getRange lexbuf) }
    | "~"                   { BNOT (getRange lexbuf) }
    | "<<"                  { SHL (getRange lexbuf) }
    | ">>"                  { SHR (getRange lexbuf) }

    (* advanced bitwise operators *)
    | "+>>"                  { SSHR (getRange lexbuf) } // signed shift right  
    | "<<>"                  { ROTL (getRange lexbuf) } // rotate left
    | "<>>"                  { ROTR (getRange lexbuf) } // rotate right   
    
    (* relational operators *)
    | "=="                  { EQU (getRange lexbuf) }
    | "!="                  { IEQ (getRange lexbuf) }
    | "<"                   { LES (getRange lexbuf) }
    | "<="                  { LEQ (getRange lexbuf) }
    | ">"                   { GRT (getRange lexbuf) }
    | ">="                  { GEQ (getRange lexbuf) }

    (* identity operators *)
    | "==="                 { IDEQU (getRange lexbuf) }
    | "!=="                 { IDIEQ (getRange lexbuf) }

    (* static cast *)
    | "as"                  { AS (getRange lexbuf) }

    (* forced cast *)
    | "as!"                 { ASBANG (getRange lexbuf) } 

    (* annotations *)
    | "@"                   { AT (getRange lexbuf) }
    | "@@"                  { ATAT (getRange lexbuf) }

    (* length operators on arrays and slices *)
    | "#"                   { LEN (getRange lexbuf) }    
    | "##"                  { CAP (getRange lexbuf) }

    (* -------------- Access operators ------------*)
    | "prev"                { PREV (getRange lexbuf) }
    | "next"                { NEXT (getRange lexbuf) }

    

    (* --------- delimiters and punctuations --------- *)

    | "{"                   { LBRACE (getRange lexbuf) }
    | "}"                   { RBRACE (getRange lexbuf) }
    | "["                   { LBRACKET (getRange lexbuf) }
    | "]"                   { RBRACKET (getRange lexbuf) }
    | "("                   { LPAREN (getRange lexbuf) }
    | ")"                   { RPAREN (getRange lexbuf) }
    | "..."                 { ELLIPSIS (getRange lexbuf) }
    | "."                   { POINT (getRange lexbuf) }
    | ":"                   { COLON (getRange lexbuf) }
    | ","                   { COMMA (getRange lexbuf) }
    | ";"                   { SEMICOLON (getRange lexbuf) }
    | "?"                   { QUEST (getRange lexbuf) }

    (* --------- literals --------- *)

    | binliteral            { BINCONST  (getLexemeAndRange lexbuf) }
    
    | octliteral            { OCTCONST (getLexemeAndRange lexbuf) }
    
    | hexliteral            { HEXCONST (getLexemeAndRange lexbuf) }

    | natliteral            { NATCONST (getLexemeAndRange lexbuf) }

    | floatliteral          { FLOATCONST (getLexemeAndRange lexbuf) }

    | hexfloatliteral       { HEXFLOATCONST (getLexemeAndRange lexbuf) }

    (*
    | stringliteral         { let lxm, rng = getLexemeAndRange lexbuf
                              let nlxm = BlechString.normalizeStringLiteral lxm
                              if checkStringLiteral(nlxm, rng) then
                                let str = nlxm.Substring(1, nlxm.Length - 2)
                                STRING ( str, rng ) 
                              else
                                EOF rng }
*)

    | '_'*['a'-'z' 'A'-'Z']+['_' 'a'-'z' 'A'-'Z' '0'-'9']* 
                            { ID (getLexemeAndRange lexbuf) }

    | '_'+                  { WILDCARD (getLexemeAndRange lexbuf) }

    (* --------- end of file and unknown tokens --------- *)

    | eof                    { EOF (getRange lexbuf) }

    | _                      { unknownToken lexbuf; 
                               Token lexbuf }

(* fjg: returns the next token after the comment, in order to make EOF available in case of unterminated comment *)
and SkipBlockComment = parse     

    | "*/"                  { commentDepth <- commentDepth - 1;
                              if commentDepth = 0 then
                                  commentStart <- None;
                                  Token lexbuf
                              else 
                                  SkipBlockComment lexbuf }
       
    | "/*"                  { commentDepth <- commentDepth + 1;
                              SkipBlockComment lexbuf }

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              SkipBlockComment lexbuf }

    | eof                   { commentNotClosed lexbuf; 
                              EOF (getRange lexbuf) }


    | chunkwithoutstarandslash
                            { SkipBlockComment lexbuf }

    | '/'                   { SkipBlockComment lexbuf }

    | "*"                   { SkipBlockComment lexbuf }



and SkipLineComment = parse
    | chunkwithoutnewline   { Token lexbuf }

and SkipLineOnError = parse
    | endofline             { let eol = EOL (getRange lexbuf) in
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              ParserContext.setErrorTokenAccepted false; 
                              eol}

    | eof                   { ParserContext.setErrorTokenAccepted false; 
                              EOF (getRange lexbuf)}

    | chunkwithoutnewline   { SkipLineOnError lexbuf }


and CollectLineDoc = parse    
    | chunkwithoutnewline   { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectLineDoc lexbuf }

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine 
                              LINEDOC (tokenBuilder.Token) }
                              
    | eof                   { eofInDocComment (tokenBuilder.Range) 
                              EOF (getRange lexbuf) }

    
and CollectBlockDoc = parse
    | chunkwithoutstar      { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectBlockDoc lexbuf }

    | "*"                   { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectBlockDoc lexbuf }
    
    | endofline             { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectBlockDoc lexbuf }
    

    | "*/"                  { BLOCKDOC (tokenBuilder.Token) }

    | eof                   { eofInDocComment (tokenBuilder.Range)
                              EOF (getRange lexbuf) }

and CollectString = parse   // TODO: Move token checking - e.g. decimal and unicode escapes, utf8endofline, ascii control chars to lexer, fjg. 18.08.20
    | endofline             { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectString lexbuf }

    | utf8endofline         { unknownToken lexbuf;
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectString lexbuf }

    | '"'                   { let lxm, rng = getLexemeAndRange lexbuf
                              tokenBuilder <- tokenBuilder.Append(lxm, rng)
                              // printf "String:\n%s" tokenBuilder.Text
                              STRING (tokenBuilder.Token) }

    | stringitems
                            { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectString lexbuf }
        

    | eof                   { eofInDocComment (tokenBuilder.Range)  // Todo: Create separate error message, fjg. 5.8.20
                              EOF (getRange lexbuf) }

    | _                      { unknownToken lexbuf; 
                               Token lexbuf }

and CollectTripleQuotedString = parse
    | endofline             { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              lexbuf.EndPos <- lexbuf.EndPos.NextLine // necessary for correct ranges
                              CollectTripleQuotedString lexbuf }
    
    | triplequotes          { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              TRIPLEQUOTEDSTRING (tokenBuilder.Token) }    

    | stringitems
                            { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              CollectTripleQuotedString lexbuf }
    
    | quotes                { tokenBuilder <- tokenBuilder.Append(getLexemeAndRange lexbuf)
                              (* if lxm = "\"\"\"" then  // Todo: Create a helper function for this, fjg. 5.8.20
                                  let tqstr = BlechString.normalizeTripleQuotedStringLiteral tokenBuilder.Text
                                  // printfn "%s" tqstr
                                  // Strip of """<string>""" to get <string>, the range contains """<string>"""
                                  STRING ( tqstr.Substring(3, tqstr.Length - 6), tokenBuilder.Range ) *)
                              CollectTripleQuotedString lexbuf }

    | eof                   { eofInDocComment (tokenBuilder.Range)  // Todo: Create separate error message, fjg. 5.8.20
                              EOF (getRange lexbuf) }

    | _                      { unknownToken lexbuf; 
                               Token lexbuf }


and FromPath = parse
    | path                  { let path, rng = getLexemeAndRange lexbuf in
                              FROMPATH {Blech.Frontend.AST.FromPath.path = path
                                        range = Range.unionRanges fromStart rng } }

    | endofline             { lexbuf.EndPos <- lexbuf.EndPos.NextLine; 
                              FromPath lexbuf }
    
    | [' ']                 { FromPath lexbuf }

    | ['\t']                { tabularUsed lexbuf; 
                              FromPath lexbuf }

    | _                     { notAPath lexbuf;
                              Token lexbuf }